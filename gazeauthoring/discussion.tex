Our gaze authoring approach could be extended in several ways. 
Our focus on directed gaze covers many important cases, and our model can approximate some others. However, integration with other models for other kinds of gaze, such as idle gaze and smooth pursuit, would improve the applicability of our approach.
%Foremost, it approximates all behavior as directed gaze and lacks explicit support for other types of gaze movements such as smooth pursuit and idle gaze. 
Our gaze inference approach complements saliency-based methods for idle gaze, such as~\cite{peters2003bottomup}, which could be utilized to refine the inference output. Moreover, while our heuristic approach to gaze inference is sufficient to obtain a plausible gaze behavior as a starting point for editing, its accuracy and sensitivity could be further improved; for example by using recorded motion and gaze data as priors for a learned model.
%The gaze behavior inferred and synthesized by the system is fully deterministic, which makes the synthesis result easier to control. However, adding probabilistic specification of certain gaze properties could facilitate authoring of more varied and believable behavior---for example, randomly generated saccades for idle gaze~\cite{lee2002eyes} and probabilistic selection of gaze target locations. Furthermore, while our gaze layering approach is able to overlay new gaze animation and preserve elements of the original body posture, it may not generalize to all scenarios. For instance, if original motion of the head contains horizontal movements such as head shakes, a gaze instance synthesized by our system will overwrite them. Our experience suggests that such gestures do not typically co-occur with directed gaze, but we believe that the current system would nonetheless benefit from a more robust and general motion adaptation formulation that would give more ability to specify which properties of the original motion should be preserved---for example, an approach based on spacetime constraints.
% TODO: add a citation? kinda hard to think of only one
%Finally, it would be fairly straightforward to 
Our gaze inference method could be adapted to operate on interactive inputs, allowing it to be used for predicting user attention and intent in virtual reality and other interactive contexts.
Our editing approach could be extended to better use captured eye movements when they are available: the current synthesis approach will replace any initial eye movements. 

The current implementation of the system in Unity serves as an adequate proof of concept, but its utility to artists would be increased by integration with a 3D animation software such as MotionBuilder or Maya. Furthermore, the system uses a custom gaze controller for motion synthesis. While the controller generates neurophysiologically plausible movements, its feed-forward design means the entire motion needs to be synthesized from start to end to obtain the final editing result. To make the system more immediate, alternative motion synthesis methods might need to be explored.

% TODO: this was in the conclusion

We have proposed an approach for adding editable, directed gaze animation to characters animated using full-body motion capture. The approach is based on the idea of modeling the gaze behavior as a sequence of gaze instances, representing gaze shifts toward targets in the scene. We have shown how this representation can be automatically inferred from the body motion and scene geometry, producing an initial gaze animation that can be refined further through manual editing. We have also described a convenient gaze editing approach which takes advantage of the representation's two key properties: abstraction of gaze pose and timing details, and anchoring the gaze behavior in the scene via target handles. Finally, we have described a method for synthesizing plausible gaze animation from this representation and adding it to the original motion. As shown in our evaluations, our approach can substantially reduce the labor and skill required to author gaze animation compared to traditional tools. Even a novice animator can endow characters with gaze at an acceptable level of quality, and it can also serve as a labor-saving tool for skilled animators by providing them with a first-guess animation they can edit further. In particular, our approach has potential applications in domains where quantity and speed of animation production are important considerations, such as television animation or animation of background and midground characters in film and games. 
