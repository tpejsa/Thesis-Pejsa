Character animation---the process of bringing drawn, sculpted, or computer-generated characters to life---forms the backbone of some of the most popular contemporary art forms, such as animated films and video games. With their proven ability to engage and entertain people irrespective of age and culture, animated characters hold potential that extends beyond storytelling media: the last two decades have witnessed a growing research and commercial interest in embodied conversational agents~\cite{original ECA paper}, animated characters that can converse with users in real time and serve in educational, marketing, and socially assistive roles. Across all these application domains, one maxim pertaining to character animation holds true: to captivate and engage the viewer, animated characters need to be \emph{believable}. Their visible behaviors must be comprised of physically and biologically plausible movements, and they must clearly convey the characters' intentions, emotions, and personalities. Believable character animation is synonymous with plausible, communicatively effective behavior, and a key component of such behavior is \emph{gaze}. This body of research contributes several new techniques for creating communicatively effective gaze behaviors for computer-generated, animated characters.

The importance of gaze in human communication is well-documented. By observing the gaze of others, people can infer the focus of their attention and understand high-level meaning behind their actions---e.g., people ground linguistic references to objects by looking at them~\cite{Hanna and Brennan, 2007, Preissler and Carey, 2005}. A person can look at objects and information in the environment and the viewer's attention will be automatically redirected toward the same objects through the mechanism of joint attention~\cite{D’Entremont et al., 2007}. Moreover, spatial and temporal distribution of gaze among different foci implicitly conveys their importance to the current activity---e.g., participants in a multiparty interaction can use their gaze and body orientation to involve a newcomer as an equal partner, or relegate them to a bystander role~\cite{sth on footing in human conversations}.
Importantly, human attention-signalling behaviors consist of more than just eye movements---people convey their attention through coordinated shifts in eye direction, head, and body posture toward targets in the environment~\cite{some papers that show this}. In this document, I refer to such coordinated, targeted eye, head, and body movements as \emph{directed gaze}.

Animated characters with appropriately designed gaze behaviors can achieve the same communicative effects. This capability of animated gaze is well-known to professional animators; in the pioneering years of animation, an oft-repeated rule of thumb at Walt Disney Animation Studios was: ``If you're short of time, spend it on the eyes. The eyes are what people watch.'' Animators expend much effort into animating believable gaze movements that capture the audience’s attention and direct it toward the most important thing on the screen. In 3D animation, gaze is typically hand-animated using inverse kinematics and keyframing. A gaze IK rig constrains the eyes to point in a specific direction, while keyframing is used to specify how this direction changes over time. The key to believable gaze is getting the timing and spatial relationships of gaze movements right, since people are highly sensitive even to small errors. Yet achieving believable gaze requires a great dea of animator expertise and effort. For this reason, manual authoring is costly. Worse yet, manual authoring scales poorly. Hand-animated gaze is valid only for the current character and scene. If we want to apply the same gaze behavior to a character with a different design (e.g., different eye size or spacing), or change the scene layout (thus altering gaze target locations), we must hand-edit the animation or recreate it from scratch. The scalability issue is even more apparent in interactive scenarios, where the gaze needs to dynamically adapt to scenario events and inputs: e.g., a virtual agent needs to be able to look at the user as they move around.

Automated synthesis methods are often a viable means of animating gaze when manual authoring is too costly or infeasible.
Such methods generally use procedural or data-driven models of human gaze to synthesize controllable gaze movements in interactive scenarios. Individual methods tend to focus on specific types of gaze movements, such as saccades or smooth pursuit. They also tend to be designed for specific scenarios, such as face-to-face conversations~\cite{a few conv. gaze papers} or crowd animation~\cite{crowd gaze}. Finally, the focus of these methods is on automated synthesis rather than supporting the authoring workflow, which makes them inapplicable in practice to non-interactive scenarios such as film animation. The objective of my research is to introduce new, complementary methods for creating animated gaze.

%Existing gaze synthesis methods are limited in various ways: they tend to focus on specific types of gaze movements, such as saccades or smooth pursuit; they do not consider how these movements coordinated with head and body posture; they are designed for automated synthesis in interactive scenarios rather than supporting animation authoring; their communicative effectiveness often lacks empirical demonstration.

Computational synthesis of gaze is hardly a novel proposition
Shortcomings of previous techniques:
- Focus on specific types of gaze movements (saccades, smooth pursuit)
- Lack of consideration for full-body motion
- Lack of consideration for variation in character design
- Focus on automation over control and authoring
- Lack of evaluation of effectiveness
We propose a broadly applicable model of gaze behavior called directed gaze - (define it)
We introduce techniques for synthesis of plausible, effective directed gaze movements
Novelties:
- Support for upper-body and whole-body movements as well - many behaviors can be described or approximated by directed gaze; not just gaze shifts, gaze aversions, saccades, fixations... but also body orientation shifts
- We consider combining gaze with existing full-body motion (though that's partially a necessity since our gaze shifts can also animate the body)
- We introduce retargeting to different character designs
- We introduce a coherent gaze authoring framework
- Effectiveness extensively evaluated in studies with human participants

We introduce techniques for 

(1) For plausibility, we need natural kinematics
(2) For effectiveness, we need control (and evaluation in user studies)


\textbf{The thesis of this disertation is that directed gaze is an effective model for synthesis and authoring of attention-signalling behaviors on animated characters.} 


Key ideas of this research

Contributions of this research

Scope and applications
