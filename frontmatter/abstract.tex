Gaze is a fundamental component of believable character animation, allowing animated characters to capture the viewer's attention and direct it toward important objects and information in the environment. The character signals its attention not just with the eyes, but also with coordinated shifts in head and body pose. Producing such richly articulated movements is a challenging problem that requires considerable animator effort and expertise. This work introduces a set of methods that simplify and automate the process of synthesizing biologically plausible, communicatively effective gaze. The key idea is to model the character's gaze behavior as \emph{directed gaze shifts}---coordinated, rotational movements of the eyes, head, and body toward targets in the scene. A kinematic, neurophysiologically-based model for synthesis of directed gaze shifts is proposed, that allows parametric control over head and body coordination. Experiments are presented which demonstrate how this model enables an animated character to effectively signal its attention through shifts in gaze direction and body orientation. Furthermore, methods are introduced that enable scalable authoring of rich gaze animation for a wide range of characters and scenarios. These include methods for adapting gaze shift kinematics to non-human and stylized character designs, as well as a comprehensive animation authoring approach, which uses directed gaze shifts as building blocks; as shown in empirical studies, this approach can automatically add plausible gaze animation to a scenario animated using full-body motion capture, and it also includes methods and tools for convenient editing of the gaze behavior.
