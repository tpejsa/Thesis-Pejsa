In this section, we describe our model for gaze shifts synthesis for ECAs. The model falls into the category of procedural, low-level models that synthesize individual gaze shifts towards targets in space. It is distinguished from prior models in that it offers intuitive parametric control over eye, head, and upper body coordination while synthesizing neurophsiologically plausible motion across the parametric range. The gaze shifts to synthesize can be specified manually by a designer, or an automated, high-level gaze model could utilize our model for synthesis of individual gaze shifts, taking advantage of its rich parametrization to produce a broader range of gaze behaviors.

The model accepts as input the properties of the gaze shift that should be synthesized, including \emph{gaze target position} (where the agent will look) and head and trunk \emph{alignments}, which specify how far each of these body parts will rotate relative to the target. Given these inputs, the model synthesizes a gaze shift which turns the agent's eyes---and potentially also head and upper body---towards the target. The animation of the gaze shift is generated using a set of kinematic laws, derived from measurements of primate gaze reported in neurophysiology research \cite{guitton1987gaze,mccluskey2007monkeys}. Articulation is achieved by incrementally rotating the joints of the eyes, neck, and lower spine towards the target; rotational increments are computed on every frame using the kinematic laws, based on the current target position relative to the agent. The approach enables the model to synthesize accurate gaze shifts even towards targets that are moving relative the agent.

Assuming the agent is a virtual character, our model only requires them to be rigged for skeletal animation and to have the appropriate set of joints. Given a rigged character with humanlike anatomic proportions, the gaze model can be used as is---although kinematic laws utilized in the model expose a number of designer-tunable constants, these do not need to be adjusted to synthesize neurophysiologically correct gaze shifts. Furthermore, in order to simplify parametric control and make the model generalize better to different characters, body joints are distributed into several groups that are controlled jointly. Neck joints (cervical vertebrae) are grouped together under the body part \emph{head}. As the head rotates over the course of a gaze shift, this rotation is distributed among the joints that constitute the head. This is based on how real humans move---head movement in humans is achieved through simultaneous rotation of all the neck joints. Similarly, trunk rotation is achieved through simultaneous rotation of the lower spine joints (lumbar vertebrae), and so these are all grouped under the body part \emph{trunk}. In the paper, when we refer to head rotation or trunk rotation, we actually refer to rotation that is distributed among the joints of the neck and lower spine.

\subsection{Eye Movements}

In this section, we describe eye movements that occur in gaze shifts as they are simulated in our model. Directed eye movements in gaze shifts are referred to as \emph{saccades}. Saccades are realized as shortest-path rotations of the eyes in their sockets towards the gaze target $T$. Position of the target, $T$, is a designer-specified parameter of the model. Figure~\ref{fig:Saccades} illustrates a saccadic eye movement. At the start (A), the eyes begin to rotate towards the gaze target simultaneously. One of the eyes reaches the target first and locks onto it (B), while the other eye continues to rotate towards the target until it has aligned with it as well (C). The opposing eye movements that occur between (B) and (C) are referred to as \emph{vergence}. We use the same kinematic model to produce both saccadic and vergence motions, although neurophysiology research has shown these are neurally distinct motions that activate different, albeit substantially overlapping areas of the brain \cite{alkan2011differentiation}.

\begin{figure*}[b]
\centering
\includegraphics[width=0.85\textwidth,page=2]{Figures/tiis14-pejsa.pdf}
\caption{Phases of an eye saccade. Dashed arrows indicate eye gaze directions, while the curved arrow indicates the direction of the rotational movement. Saccade proceeds as follows: (A) Eyes begin to rotate towards the target. (B) First eye has reached the target. (C) Both eyes have reached the target.}
\label{fig:Saccades}
\end{figure*}

At the end of the gaze shift, both eyes are locked onto the gaze target. If the relative position of the target and the eyes changes due to head motion, the eyes automatically move in the opposite direction to compensate and maintain their lock on the target. This eye movement is known as the \emph{vestibulo-ocular reflex} (VOR) and its function is to stabilize the image on the eye's retina during movement.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth,page=4]{Figures/tiis14-pejsa.pdf}
\caption{Velocity profiles for the motion of different body parts. Left: Eye velocity. Right: Head and trunk velocities. Mathematical expressions for the profiles are given in equations~\ref{eq:EyeVelocity} and~\ref{eq:HeadTrunkVelocity}.}
\label{fig:VelocityProfile}
\end{figure*}

Saccadic motion of the eyes follows the piecewise polynomial velocity profile shown in Figure~\ref{fig:VelocityProfile}, left. Peak eye velocity $V_{\mathrm{max},E}$ is computed at the start of the gaze shift from the amplitude of the upcoming eye movement. This is in accordance with human gaze shifts, which take a similar amount of time to complete, irrespective of amplitude. Human saccades are extremely fast---peak eye velocity can be as high as 900$^{\circ}/s$ for large gaze shifts \cite{bahill1975main}.
% TODO: maybe add a brief discussion of how velocities are chosen, incl. stylized gaze velocities?

We compute the peak eye velocity using the following formula, derived from measurements of gaze kinematics reported by \citet{guitton1987gaze}:

\begin{eqnarray} \label{eq:AndristVmaxE}
V_{\mathrm{max},E} &=& (\frac{2}{75} A_{\mathrm{min}} + \frac{1}{6}) V_{0,E} \\
A_{\mathrm{min}} &=& \mathop{min}( \mathop{min}_{j \in \mathrm{Eyes}}(D_j), \mathrm{OMR} ) \nonumber
\end{eqnarray}

$V_{0,E}$ is an overridable eye-velocity parameter, which we keep at the default value of 150$^{\circ}/s$, while $A_{\mathrm{min}}$ is the estimated amplitude of the eye movement. Eyes are mechanically restricted in how far they can rotate in their sockets. The maximum range of eye movement is referred to as \emph{ocular motor range} (OMR), and it is between 45$^{\circ}$ and 55$^{\circ}$ in any direction. When the gaze target lies beyond the eyes' motor range, we set eye movement amplitude $A_{\mathrm{min}}$ to be equal to OMR value; otherwise, we set it to the lower of the angular distances $D_j$ between initial eye gaze direction and target direction.

\subsection{Eye-Head Coordination}

\begin{figure*}[b]
\centering
\includegraphics[width=0.9\textwidth,page=3]{Figures/tiis14-pejsa.pdf}
\caption{Movement phases of the eyes and head in a gaze shift.}
\label{fig:AndristGazeModel}
\end{figure*}

When gazing at a target that lies beyond the eyes' OMR, some head movement must occur during the gaze shift to enable the eyes to reach the target. However, as discussed in Section~\ref{sec:RelatedWorkNeurophys}, head movements do not occur solely for mechanical reasons; otherwise, the head would always rotate only the minimal amount needed to see the target. Gaze shifts often involve much greater head movements because head orientation is part of the human attention cueing mechanism \cite{hietanen1999does}. The amount of head movement in a gaze shift therefore has important implications for how the gaze shift is perceived. One of the key aspects of our model is capturing the coupling between eye and head movements during gaze shifts.

In this section, we describe how the coordinated eye and head movements are implemented in the model. At the start of a gaze shift, the designer specifies the values of two control parameters: gaze target position in world space and head alignment $\alpha_H$. Head alignment specifies how much the head should participate in the gaze shift. At $\alpha_H = 0$ the head will rotate only the minimal amount needed to permit the eyes to see the target (so the agent will look at the target ``out of a corner of the eye''). For $\alpha_H = 1$ the head will be fully aligned, causing the agent to completely face the target.

The gaze shift consists of several phases (Figure~\ref{fig:AndristGazeModel}). At the start (A), both the eyes and head begin rotating towards the target. Since the eyes move much faster than the head, they quickly reach either the target or the limit of their OMR, set to be between 45$^{\circ}$ and 55$^{\circ}$ in any direction (B). There they remain blocked until the head catches up. Eventually the head rotates far enough to bring the eyes into alignment with the target (C). Vestibulo-ocular reflex (VOR) locks the eyes onto the target as the head continues to align. Depending on the specified head alignment, the head will either stop moving immediately ($\alpha_H = 0$) or continue rotating until it has reached the required alignment with the target (D).

Throughout the entire gaze shift, head motion follows a piecewise polynomial velocity profile similar to the one for the eyes (Figure~\ref{fig:VelocityProfile}, right). Peak head velocity $V_{\mathrm{max},H}$ is computed at the start of the gaze shift; it is proportional to the expected amplitude of the head movement \cite{guitton1987gaze}:

\begin{eqnarray} \label{eq:AndristVmaxH}
V_{\mathrm{max},H} &=& (\frac{4}{3} \frac{D_H}{50} + \frac{2}{5}) V_{0,H}
\end{eqnarray}

$D_H$ is rotational amplitude of the head or distance it will rotate over the course of the gaze shift. Velocity parameter $V_{0,H}$ is designer-specifiable, with the default value of 50$^{\circ}/s$.

\subsubsection{OMR Estimation}

As mentioned, human eyes are mechanically limited in their movements by the OMR, which is estimated to be between $45^{\circ}$ and $55^{\circ}$. Encoding these OMR values as static parameters into virtual humans is not sufficient, however, as the effective OMR depends on the initial position of the eyes at the start of the gaze shift and may fluctuate over the course of the gaze shift. These fluctuations are a product of a neural (as opposed to mechanical) limitation imposed on eye motion \cite{guitton1987gaze}. We define initial eye position (IEP) as rotational offset of the eyes from the central orientation (when the eyes are looking ``straight ahead''). We define IEP to be non-zero only when the eyes are \emph{contralateral} to the target, i.e., their initial orientation is on the opposite side of the center from the target. The relationship between IEP and neurally limited OMR is obtained from \citet{guitton1987gaze}:

\begin{eqnarray} \label{eq:AndristOMRIEP}
\mathrm{OMR} &=& \mathrm{OMR}_0 (\frac{1}{360} \mathrm{IEP} + 0.75)
\end{eqnarray}

where $\mathrm{OMR}_0$ is the mechanical OMR value (between $45^{\circ}$ and $55^{\circ}$ by default).

\subsubsection{Head Latency}

In human gaze shifts, the head typically begins to move with some delay relative to the start of eye movements. This delay, which we refer to as \emph{head latency}, typically ranges between 0 and 100 $ms$ and depends on task properties and individual characteristics---factors including gaze shift amplitude, predictability and saliency of the target, vigilance of the subject, and whether the gaze shift is forced or natural \cite{pelz2001coordination,zangemeister1982types}. In rare cases, head latency can be negative; that is, the head starts moving \emph{before} the eyes. Studies that evaluated correlations between head latency and target modality found that eyes tend to lead the head when people orient towards visual targets, whereas the head tends to lead when orienting towards auditory targets~\cite{goldring1996combined,goossens1997human}.

Our gaze model exposes head latency as an additional eye-head coordination parameter $\tau_H$. By setting a value $\tau_H > 0$, the designer can designate the head to start moving after the eyes, while for $\tau_H < 0$ the head will start moving before the eyes during to start the gaze shift. In the experiments presented in the current work, this parameter is held constant at its default value of zero.

\subsection{Upper Body Coordination}

Gaze shifts often incorporate upper body movements in addition to eye and head movements. Similar to changes in head orientation, changes in upper body orientation do not occur simply because they are necessary mechanically, but because they demonstrate large shifts in attention and mutual involvement \cite{kendon1973visible}.

To support upper body movements, we make several extensions to the model of eye-head coordination described above. Development of these extensions was largely guided by existing neurophysiological measurements of gaze and our own experimentation. We mostly referred to the study by \citet{mccluskey2007monkeys}, who investigated eye, head, and body coordination during gaze shifts of rhesus monkeys with the expectation that the results would apply to other species of primates.

Thus, we introduce a new body part---the trunk, which has its own alignment parameter $\alpha_T$. Trunk alignment specifies the participation of the trunk in the gaze shift. At $\alpha_T = 0$ the trunk will rotate only the minimal amount, while $\alpha_T = 1$ will make the trunk fully align with the target.

It has been shown that the amount of trunk movement increases with gaze shift amplitude \cite{mccluskey2007monkeys}. Small gaze shifts do not engage the trunk at all. The minimal amount of trunk rotation as a function of angle in degrees is computed as follows:

\begin{align} \label{eq:TrunkDmin}
D_{T,\mathrm{min}} = \begin{cases}
0.43 \mathop{exp}(0.03 D) + 0.19 & \mbox{iff } D \geq 40^{\circ} \\
0.08 D - 1.56 & \mbox{iff } 20^{\circ} \leq D < 40^{\circ} \\
0 & \mbox{iff } D < 20^{\circ} \\
\end{cases}
\end{align}

where $D$ is the overall gaze shift amplitude, estimated as the angle between current and target eye gaze direction. Note that for gaze shifts where $D \geq 20^{\circ}$, the trunk will rotate by the amount $D_{T,\mathrm{min}}$ even if $\alpha_T = 0$. For higher values of $\alpha_T$, the trunk will rotate towards the target even more.

\begin{figure*}
\centering
\includegraphics[width=1\textwidth,page=5]{Figures/tiis14-pejsa.pdf}
\caption{Movement phases of the eyes, head, and trunk in a gaze shift. Dashed area indicates that the trunk may stop moving before or after the head.}
\label{fig:OurGazeModel}
\end{figure*}

The sequence of phases in an upper-body gaze shift is shown in Figure~\ref{fig:OurGazeModel}. At the start of the gaze shift (A), the trunk is stationary for a period of $\tau_T$ $ms$, after which it begins to move. The trunk continues to move until it reaches the correct orientation relative to the target, as specified by $\alpha_T$. The trunk moves more slowly than the eyes and head, so it may continue to move even as the eyes and head reach and lock onto the target (D, E). However, for gaze shifts with low latency and little trunk movement, the trunk may reach its final orientation while the head is still moving.

Since prior studies of upper body motion do not provide an exact profile of trunk velocity, we apply the peaked profile used for head velocity to trunk motion as well (Figure~\ref{fig:VelocityProfile}, right). Peak trunk velocity $V_{\mathrm{max},T}$ should be lower than peak head velocity, but it should still be proportional to rotational amplitude \cite{mccluskey2007monkeys}. Guided by these principles and experimentation, we derived the following expression for the peak trunk velocity:

\begin{eqnarray} \label{eq:TrunkVmax}
V_{\mathrm{max},T} &=& (\frac{4}{3} \frac{D_j}{15} + 2) V_{0,T}
\end{eqnarray}

where $D_j$ is the rotational amplitude of the trunk, while $V_{0,T}$ is a designer-specifiable velocity value, with the default value of 15$^{\circ}/s$.

\subsubsection{Trunk Latency}

\citet{mccluskey2007monkeys} found that the trunk does not begin to move at the same time as the eyes and head, but with some latency $\tau_T$ that depends on factors such as gaze shift amplitude and target predictability. In our experiments, we found that trunk latency value had great impact on naturalness of upper body motion, so we could not simply set it to a fixed value. Instead, based on the results from the McCluskey study, we compute trunk latency (in milliseconds) as follows:

\begin{eqnarray} \label{eq:TrunkLatency}
\tau_{T} = 0.25 D + 47.5
\end{eqnarray}

where $D$ is gaze shift amplitude. It follows from the above equation that in large gaze shifts, the trunk is going to trail behind the head and eyes more.

\subsection{Animating a Gaze Shift}

The parameters described above specify a complete gaze shift. Motion synthesis is accomplished through feed-forward control, which drives the joints of the eyes, head, and trunk towards the target at angular velocities computed from their velocity profiles. Each joint has a numerical index $j$: left and right eye have joint indices 0 and 1, respectively, while joints lower in the body (head, trunk) are assigned incrementally higher indices. Joint orientations are represented using quaternions---four-dimensional numbers that encode the angle and axis of a 3D orientation. We denote the orientation of the joint $j$ at the start of the gaze shift $q_{S,j}$. We also define the \emph{target orientation} $q_{T,j}$, which is the final orientation of the joint at the end of the gaze shift. As the gaze shift progresses, the joint rotates from the source orientation to the target orientation---its current orientation gets updated on every animation frame. We denote the current orientation of joint $j$ at frame $i$ as $q^i_{j}$.

\subsubsection{Computing Target Joint Orientations}
\label{sec:ModelTargetOrientations}

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth,page=6]{Figures/tiis14-pejsa.pdf}
\caption{Computing target orientation $q_{T,j}$ for a joint $j$. Left: Procedure for the eyes. $q_{\mathrm{full},j}$ is the orientation that fully aligns the eye with the gaze target. However, since the target lies beyond the eye's OMR, $q_{\mathrm{full},j}$ is clamped to the OMR limit, giving us the target orientation $q_{T,j}$. Right: Procedure for trunk joints. $q_{\mathrm{min},j}$ is the minimal orientation the trunk must achieve, while $q_{\mathrm{full},j}$ is the orientation that fully aligns the trunk with the gaze target. The latter is given by the vector $e$ pointing from the eye centroid to the target. Target orientation $q_{T,j}$ is computed by interpolating between minimal and fully aligned orientations using the alignment parameter $\alpha_T$.}
\label{fig:TargetRot}
\end{figure}

Before the gaze shift begins, we compute the target orientation for each joint $q_{T,j}$. For the eyes, the computation proceeds as follows (Figure~\ref{fig:TargetRot}, left). We compute the fully aligned eye orientation $q_{\mathrm{full},j}$---the orientation at which the eye is staring directly at the target. If the target lies within the eye's OMR, i.e., if it is reachable by the eyes, then $q_{T,j} = q_{\mathrm{full},j}$. If not, then $q_{T,j}$ is obtained by clamping $q_{\mathrm{full},j}$ to the OMR limit (computed using Equation~\ref{eq:AndristOMRIEP}).

The method of computing target orientations for trunk joints is illustrated in Figure~\ref{fig:TargetRot}, right. We first compute the fully aligned trunk orientation $q_{\mathrm{full},j}$, which is the orientation the trunk joint would have if it were completely facing the target. We choose $q_{\mathrm{full},j}$ such that the facing direction of the joint $j$ at that orientation is parallel to the vector $e$ pointing from the eye centroid to the target. We also know the trunk must rotate by a minimal amount $D_{T,\mathrm{min}}$ (see Equation~\ref{eq:TrunkDmin}), which we use to compute minimal trunk orientation $q_{\mathrm{min},j}$. Target orientation lies between the minimal orientation $q_{\mathrm{min},j}$ and fully aligned orientation $q_{\mathrm{full},j}$, depending on the trunk alignment parameter $\alpha_T$. We can compute it using spherical linear interpolation ($\mathop{slerp}$), an operation which interpolates a pair of quaternions along the shortest arc, using an interpolation parameter that ranges from 0 to 1. We use $\mathop{slerp}$ to interpolate between $q_{\mathrm{min},j}$ and $q_{\mathrm{full},j}$ using trunk alignment $\alpha_T$ as the interpolation parameter:

\begin{eqnarray} \label{eq:TrunkTargetRot}
q_{T,j} &=& \mathop{slerp}( q_{\mathrm{min},j}, q_{\mathrm{full},j}, \alpha_{T} )
\end{eqnarray}

$q_{\mathrm{min},j}$ lies between the source orientation $q_{S,j},$ and the fully aligned orientation $q_{\mathrm{full},j}$ and can also be computed using $\mathop{slerp}$:

\begin{eqnarray} \label{eq:TrunkMinRot}
q_{\mathrm{min},j} &=& \mathop{slerp}(q_{S,j}, q_{\mathrm{full},j}, \frac{D_{T,\mathrm{min}}}{\angle(q_{S,j}, q_{\mathrm{full},j})})
\end{eqnarray}

where the symbol $\angle$ denotes the angular distance between two quaternions.

The method for head joints is nearly identical to that for trunk joints (Figure~\ref{fig:TargetRot}, right), with two differences. First, we use the head alignment parameter $\alpha_H$ instead of trunk alignment $\alpha_T$. Second, $q_{\mathrm{min},j}$ is the minimal head orientation needed to bring the eyes into alignment with the gaze target; that is, it is computed from the highest rotational difference between each eye's $q_{\mathrm{full},k}$ and OMR-clamped $q_{T,k}$ ($k \in \mathrm{Eyes}$).

\subsubsection{Updating Joint Orientations}

As the gaze shift executes, joint orientations are updated at the constant frame rate of 60 \emph{fps}. On every frame, the update algorithm iterates through all the joints in the hierarchy, starting at the lowermost trunk joint and ending with the eyes. If the joint is a trunk joint or head joint, the algorithm checks whether its latency time ($\tau_T$ or $\tau_H$, respectively) has expired---if it has, the joint is ready to begin rotating. We compute the joint's current rotational velocity $V^i_j$, where $i$ is the current frame index, using the appropriate velocity profile. Then we incrementally rotate the joint towards its target orientation $q^i_{T,j}$. Rotating a joint affects the target orientations of subsequent joints ($q^i_{T,j-1}$, $q^i_{T,j-2}$, etc.), which therefore need to be recomputed. The gaze shift ends when both eyes have aligned with the target and all head and trunk joints have reached their target orientations.

The velocity profiles used to compute $V^i_j$ for each joint are shown in Figure~\ref{fig:VelocityProfile}. We derived these piecewise polynomial profiles as approximations of eye and head velocity profiles reported in literature \cite{kim2007head,lee2002eyes}. The velocity profile for the eyes has the following mathematical expression:

\begin{align} \label{eq:EyeVelocity}
V^i_j = \begin{cases}
(r^i_j + 0.5)V_{\mathrm{max},E} & \mbox{iff } r^i_j < 0.5 \\
(8{r^i_j}^3 - 18{r^i_j}^2 + 12r^i_j - 1.5)V_{\mathrm{max},E} & \mbox{iff } r^i_j \geq 0.5
\end{cases}
\end{align}

The velocity profile for the head and trunk (Figure~\ref{fig:VelocityProfile}, right) is defined as follows:

\begin{align} \label{eq:HeadTrunkVelocity}
V^i_j = \begin{cases}
(1.5r^i_j + 0.25)V_{\mathrm{max},j} & \mbox{iff } r^i_j < 0.5 \\
(12{r^i_j}^3 - 27{r^i_j}^2 + 18r^i_j - 2.75)V_{\mathrm{max},j} & \mbox{iff } r^i_j \geq 0.5
\end{cases}
\end{align}

$r^i_j$ is the gaze shift progress parameter, which monotonically increases from 0 to 1 over the course of the gaze shift. Joint $j$ is considered to have reached the target when $r^i_j = 1$. The parameter $r^i_j$ is updated on every frame based on angular distance covered by the joint. The update equation is as follows:

\begin{eqnarray} \label{eq:RotProgressUpdate}
r^{i+1}_j &=& r^i_j + \frac{\Delta t \cdot V^i_j}{\angle(q_{S,j}, q^i_{T,j})} c_j \\
c_j &=& \frac{2(N_j-j+o_j)}{N_j(N_j+1)} \nonumber
\end{eqnarray}

where $\Delta t$ is time since the last update, $N_j$ is the number of joints in the current body part, and $o_j$ is the index of the topmost joint in the current body part. For example, the trunk might consist of three joints ($N_j = 3$) linked in a chain, with indices starting at $o_j = 4$ for the topmost joint and ending at 6 for the lowermost joint. As we update the orientation of each joint, we multiply its parameter increment by the \emph{joint contribution} $c_j$ to ensure that overall rotation of the body part is distributed among its joints. The joint contribution $c_j$ will have a higher value for joints that have lower index $j$, meaning they are higher up in the body and must contribute more to the overall rotation of the body part. In our example with the three-joint trunk, contributions of each trunk joint will be $\frac{1}{2}$, $\frac{1}{3}$, and $\frac{1}{6}$, respectively. Note that for the eyes, which are not joint chains but single joints, we always have $N_j = 1$ and hence $c_j = 1$.

Having computed the rotation progress $r^{i+1}_j$ for each joint, we can update its current orientation by interpolating between the starting orientation $q_{S,j}$ and the target orientation $q_{T,j}$:

\begin{eqnarray} \label{eq:RotUpdate}
q^{i+1}_j = \mathop{slerp}(q_{S,j}, q^i_{T,j}, r^{i+1}_j)
\end{eqnarray}

When a joint's orientation is updated, target orientations of its children also need to be updated, because the children have now been moved closer to the target. This also has the advantage of compensating for relative motion of the target: if the gaze shift is layered onto other body animation (e.g., walking or idle motion) or if the target itself is moving, continually recomputing joint target orientations ensures that the model accurately drives the joints towards the target. First we recompute fully aligned orientations $q^{i+1}_{\mathrm{full},j}$ and then we compute the updated target orientation $q^{i+1}_{T,j}$ as follows:

\begin{eqnarray} \label{eq:TargetRotUpdate}
q^{i+1}_{T,j} &=& \mathop{slerp}(q_{S,j}, q^{i+1}_{\mathrm{full},j}, \frac{D^i_j}{\angle(q_{S,j}, q^i_{\mathrm{full},j})}) \\
D^i_j &=& \angle(q_{S,j}, q^i_{T,j}) \nonumber
\end{eqnarray}

The parameter $r^i_j$ must also be re-normalized by multiplying it with $D^i_j / D^{i+1}_j$.

An additional consideration in our model is dynamic OMR. \citet{guitton1987gaze} found that OMR gets narrower as head velocity increases. We simulate this property in our model and recompute the OMR on every frame using the following equation:

\begin{eqnarray} \label{eq:OMRUpdate}
\mathrm{OMR}^{i+1} &=& \mathrm{OMR}^i (-\frac{1}{600} V^i_j + 1)
\end{eqnarray}

where $V^i_j$ is the current head velocity, computed using Equation~\ref{eq:HeadTrunkVelocity}.

\subsection{Ancillary Components of the Model}

In addition to the main component of the model, which synthesizes gaze shifts as coordinated eye, head, and upper body movements, our gaze model also features ancillary components designed to increase the realism of the agent's behavior. The first of these components is a blink controller, which generates two types of behavior:

\begin{enumerate}
\item \emph{Gaze-evoked eye blinks} -- These eye blinks occur during saccades, and their hypothesized purpose is to lubricate the cornea and protect the eye during movement \cite{evinger1994lookleap}. We generate gaze-evoked blinks probabilistically using the distribution proposed by \citet{peters2010animating}.
\item \emph{Idle eye blinks} -- These eye blinks occur when the eyes are not in a saccade. They are generated using an exponential distribution at the constant average rate of 20 blinks/$s$ \cite{bentivoglio1997blinkrate}.
\end{enumerate}

The second ancillary component is an idle gaze generator, an implementation of the Eyes Alive model presented by \citet{lee2002eyes}. This component generates random saccades based on a statistical model of idle gaze. Individual saccades are synthesized by our own model. The idle gaze behavior contributes to realism because it prevents the agent from continually staring at the same target; rather, the agent will periodically avert its gaze before looking back at the original target after a short time.