A \emph{directed gaze shift} is an intentional redirection of gaze toward a target (object or information) in the environment, realized as a coordinated, rotational movement of the eyes, head, and potentially also torso and feet. Human attending behavior is realized as a sequence of such gaze shifts. Subtle variations in timing and spatial relationships of the different body parts (eyes, head, torso, feet) have significant effects on how the gaze behavior is perceived and what it communicates to observers. For example, glancing at a person out of the corner of the eye is not the same as looking at them head-on: the latter behavior suggests a much greater degree of interest and involvement with the object. To perform effectively as game characters, film characters, and embodied conversational agents, 3D animated characters require similarly rich gaze behaviors. Methods for computational synthesis of such behaviors must achieve two key properties: first, they must produce gaze movements that look biologically accurate and second, they must afford a sufficient degree of control over their communicative effects, actuated through subtle variations in their spatial and timing properties.

In this chapter, I present a novel model for synthesis of directed gaze shifts for animated characters, which achieves the properties of naturalness and parametric control. It is a procedural animation model that uses a set of kinematic laws to generate biologically plausible gaze shift movements without the use of motion capture data. The kinematic laws are informed by neurophysiological measurements of human gaze. The model also affords rich parametric control over coordinated movements of the eyes, head, torso, and feet, enabling an animated character to perform a wide range of attending behaviors: from glancing out of the corner of the eyes, to turning their entire body to face a target of interest. The model exposes a set of \emph{alignment parameters}, which the designer can use to define how much the agent's head, torso, and feet will participate in a gaze shift. Figure~\ref{fig:GazeShiftExamples} illustrates the usage of these parameters to produce significantly different gaze shifts. Since the model is of the low-level variety, it can be utilized for manual synthesis of individual gaze shifts, or it can be integrated with an automated, high-level model for production of complex gaze behaviors.

\begin{figure*}
\centering
\includegraphics[width=1\textwidth,page=1]{gazemodel/Figures/tiis14-pejsa.pdf}
\caption{Examples of gaze shifts synthesized using our model. All gaze shifts are toward the same target (the red sphere). (1) Initially the agent maintains eye contact with the observer. (2) Gaze shift to the side with low value of the head alignment parameter. (3) Gaze shift in the same direction, but with high head alignment value. (4) Gaze shift in the same direction with a high torso alignment value. (5) Gaze shift in the same direction with a high whole-body alignment value.}
\label{fig:GazeShiftExamples}
\end{figure*}

The remainder of the chapter is organized as follows: I present the technical details of the gaze shift model (Section~\ref{sec:GazeShiftModel}), followed by two evaluations of the model's communicative capabilities (Sections~\ref{sec:GazeShiftModelEval1} and~\ref{sec:GazeShiftModelEval2}), and I conclude with a discussion (Section~\ref{sec:GazeShiftModelDiscussion}).
