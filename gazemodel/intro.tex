A \emph{directed gaze shift} is an intentional redirection of gaze toward a target (object or information) in the environment, realized as a coordinated, rotational movement of the eyes, head, and potentially also torso and feet. Human attending behavior can be described as a sequence of such gaze shifts. Subtle variations in timing and spatial relationships of the different body parts (eyes, head, torso, feet) have significant effects on how the gaze behavior is perceived and what it communicates to observers. For example, glancing at a person out of the corner of the eye is not the same as looking at them head-on: the latter behavior suggests a much greater degree of interest and involvement with the object. To perform effectively as game characters, film characters, and embodied conversational agents, 3D animated characters require similarly rich gaze behaviors. Models for computational synthesis of such behaviors must achieve three key properties: first, they must produce gaze movements that look biologically plausible; second, they must accurately communicate the character's attention direction; and third, they must afford a sufficient degree of control over the communicative effects of gaze, realized through variations in its spatial and timing properties.

In this chapter, I present a novel model for synthesis of directed gaze shifts for animated characters, which achieves the properties of plausibility, communicative effectiveness, and parametric control. It is a procedural animation model that uses a set of kinematic laws to generate biologically plausible gaze shift movements without the use of motion capture data. The kinematic laws are informed by neurophysiological measurements of human gaze. The model also affords rich parametric control over coordinated movements of the eyes, head, torso, and feet, enabling an animated character to perform a wide range of attending behaviors: from glancing at a target out of the corner of the eyes, to turning their entire body to face the target. The model exposes a set of \emph{alignment parameters}, which can be used to define how much the agent's head, torso, and feet will participate in a gaze shift. Figure~\ref{fig:GazeShiftExamples} illustrates the usage of these parameters to produce significantly different gaze shifts. Since the model is of the low-level variety, it can be utilized for synthesis of individual gaze shifts, or it can be integrated with an automatic, high-level model for production of complex gaze behaviors.

\begin{figure*}
\centering
\includegraphics[width=1\textwidth,page=1]{gazemodel/Figures/tiis14-pejsa.pdf}
\caption{Examples of gaze shifts synthesized using our model. All gaze shifts are toward the same target (the red sphere). (1) Initially the agent maintains eye contact with the observer. (2) Gaze shift to the target with a low value of the head alignment parameter. (3) Gaze shift in the same direction, but with a high head alignment value. (4) Gaze shift in the same direction with a high torso alignment value. (5) Gaze shift in the same direction with a high whole-body alignment value.}
\label{fig:GazeShiftExamples}
\end{figure*}

In the remainder of this chapter, I present the technical details of the gaze shift model (Section~\ref{sec:GazeShiftModel}), followed by two evaluations of the model's naturalness and communicative effectiveness (Sections~\ref{sec:GazeShiftModelEval1} and~\ref{sec:GazeShiftModelEval2})\footnote{Portions of this chapter were published in~\citet{pejsa2015gaze}. The gaze shift model was built and evaluated in collaboration with Sean Andrist.}.
