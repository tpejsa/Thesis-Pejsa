\subsection{Gaze Model}

The gaze model presented in the current work can synthesize gaze shifts that incorporate parametrically controllable eye, head, and upper body movements, which have been shown to have the communicative accuracy of real human gaze (Section~\ref{sec:Study1}). As such, the model is a suitable building block for gaze behaviors of embodied conversational agents, which are designed by composing sequences of gaze shifts synthesized by the model. Designers can compose these behaviors manually to accompany a predefined interaction, as we did in studies 2 and 3. These behaviors could also be generated automatically by a high-level model, which would specify gaze targets and gaze shift timings, while the synthesis of actual gaze shifts would be accomplished by our low-level model. For example, \citet{andrist2013aversion} employed the model as part of their gaze aversions controller for ECAs, which triggers conversational gaze aversions based on a set of probability distributions.

The model as presented in the current paper is only applicable to agents with realistic, humanlike designs. Applying the gaze shifts synthesized by the model to stylized, cartoon-like embodiments would result in animation artifacts due to the exaggerated and unrealistic proportions of such characters. We have since developed a set of motion adaptation techniques for gaze that allow the model to work even on stylized embodiments \cite{pejsa2013stylized}. As part of that endeavor, we conducted a validation study of the extended model similar to the one described in Section~\ref{sec:Study1}, which showed that gaze adapted to stylized agents has the same communicative accuracy and perceived naturalness as the gaze of realistically proportioned, humanlike agents.

Although the presented model offers a comprehensive solution for coordination of the eyes, head, and upper body during gaze shifts, there is room for further extensions. Specifically, the model could be extended to also animate pelvis orientation, as well as orientation of the whole body through repositioning of the feet. These extensions are necessary to have a truly comprehensive model of attention shifts, as we infer the direction of attention of others by observing the positioning of their entire body \cite{langton2000eyes,hietanen2002social,pomianowska2011socialcues}. Extending our model to incorporate whole-body orientation would require the introduction of new alignment parameters for controlling whole-body coordination, as well as improving the animation techniques employed in the model. One shortcoming of the current model is that upper body movements lack naturalness compared to eye and head movements. This is mainly due to the complexity of the human body, which makes purely procedural animation approaches inadequate for animating body orientation in a natural and humanlike way. One possible solution is to employ a synthesis-by-example approach, which would synthesize novel gaze shift motions from example motions obtained using motion capture \cite{pejsa2010sbe}. The challenge of synthesis-by-example approaches is in achieving sufficient control over motion, which can be difficult in that the range of synthesizeable motions is limited by the motion capture examples available.

\subsection{Studies of Gaze for ECAs}

Having built our model and validated it in Study 1, we employed it in two studies where we manipulated the model's alignment parameters to manage the attention of the participants and thus control subjective and objective task outcomes. In Study 2, the model's head alignment parameter was manipulated to produce several distinct patterns of gaze behavior. Affiliative gaze emphasized eye contact and triggered feelings of affiliation between the participant and agent, leading to higher subjective evaluations of the agent. Referential gaze emphasized information in the environment and caused the participant to form stronger associations between the information and verbal references, leading to better recall of information from the interaction. These results inform the designer as to how they can manipulate the agent's gaze behavior using a model parameter---head alignment---to manage a person's attention over the course of an interaction. If the designer judges that it is more important for a person to build a strong relationship with the agent, they can employ higher head alignment values for gaze shifts that establish eye contact. On the other hand, if it is more important for a person to pay attention to objects in the environment, the designer can use higher head alignment values for gaze shifts towards these objects.

In Study 3, we manipulated the model's trunk alignment parameter to control the amount of upper body reorientation in gaze shifts towards objects in the environment. The agent would look at objects either by directing its eyes and head towards the objects while keeping its upper body oriented to the participant, or by turning the eyes, head, and upper body towards the objects by a minimal or large amount. In the latter case, the agent was perceived as expressing  more interest in the objects in question, indicating that a change in upper body orientation acts as a significant attention cue. What is more, even a very small change in body orientation led to significant increases in perceived interest, while for large changes in body orientation those increases were greater. These findings suggests that the designer can manipulate trunk alignment to continuously vary the perception of the agent's interest, analogous to how head alignment manipulation can be used to control information recall and affiliation. Furthermore, they suggest that attention cueing effects could be strenghtened further by introducing reorientation of the agent's entire body.

The significance of our studies is in that they show how ECA's gaze can trigger beneficial social and cognitive processes and lead to desired interaction outcomes, and also in that they inform designers as to how they can control these outcomes in a continuous way by manipulating specific model parameters---head alignment and trunk alignment. Furthermore, these manipulations only affect the spatial coordination properties of individual gaze shifts, while the sequence and timings of gaze shifts remain unchanged. The studies therefore illustrate how manipulating these underexplored properties of gaze can significantly enhance an agent's communicative function.

Our work forms a strong basis for continued research in gaze for ECAs. In particular, the presented model, with its demonstrated effectiveness in eliciting strong social and cognitive effects in humans interacting with the agent, can serve as a building block of gaze mechanisms that in turn facilitate more complex conversational processes, such as floor management and establishment of conversational roles. The previously mentioned gaze aversion model by \citet{andrist2013aversion} employed the current gaze shift model to synthesize conversational gaze aversions in face-to-face conversations. This work showed that an agent can use gaze aversions in an interview-style interaction to achieve smoother turn-taking, higher disclosure, and improved subjective perceptions of the agent. We believe that even more powerful conversational mechanisms can be constructed through incorporation of body reorientation, which serves as a powerful attention cue in the context of multiparty interaction. Prior research in the social sciences has shown that people reorient their bodies to establish conversational roles and reconfigure conversational formation \cite{kendon1973visible,kendon2010spacing}. Research in human-robot interaction \cite{kuzuoka2010reconfiguring} has shown that humanlike robots can achieve the same. This ability is particularly important in a dynamic setting, where parties can join or leave the conversation at any time and conversational roles fluctuate constantly---for example, agents used in the service industry, educational and guide agents, and avatars in online games and virtual worlds. We believe the current work on head and body orientation in gaze shifts presents a solid basis for exploration of issues in multiparty interactions with an embodied conversational agent.

% TODO: this is from the conclusion

Humans employ gaze cues to communicate their attention direction, initiate eye contact, and establish reference and joint attention when they interact. By doing so, they trigger important social and cognitive processes, such as positive feelings of affiliation and improved learning of information from speech and environment. The fundamental unit of these behaviors is the gaze shift, which consists of coordinated movements of the eyes, head, and upper body. Interpretation of gaze in communication depends not only on eye movements (saccades), but also on movements of the head and body that occur in concert with saccades, as humans infer attention direction of others by integrating information about the orientation of their eyes, head, and body.

In the current work, we built a computational model for synthesis of ECA's gaze shifts that enables the designer to parametrically control how the eyes, head, and upper body coordinate during the gaze shift. The model exposes head and trunk alignment parameters, which specify how much the head and trunk will turn during the gaze shift, respectively. A validation study with human participants showed that the model generates gaze that conveys attention direction as accurately as real human gaze and achieves improvements in naturalness over a state-of-the-art model. Moreover, we conducted further two studies with human participants to demonstrate that control over the coordination parameters in agent's gaze shifts affords better management of the participants' attention, which can be used to achieve desired social and cognitive effects in participants interacting with the agent.

The value of our work lies not only in the model of gaze shifts that offers rich parametric control and enables improvements in agent's task performance and subjective perceptions, but also in that we specifically demonstrate how eye-head and eye-body coordination properties of gaze shifts can be manipulated in a principled and continuous way to manage the attention of humans interacting with the agent in order to achieve desired interaction outcomes. A gaze model enabling manipulation of these properties can serve as a building block of larger mechanisms of social gaze, such as referential gaze for conveying information embedded in the environment, mutual gaze for building affiliative relationships between the agent and people, and floor management gaze in two-party and multiparty conversations.