Shifts in eye gaze direction and body orientation are building blocks of nonverbal behaviors humans rely on to initiate and conduct conversations. When two participants initiate a conversation, they position and orient their bodies in an F-formation~\citep{kendon1990conducting}, defined as a spatial arrangement creating a space between them to which they have equal, direct, and exclusive access. When another participant joins the conversation, the others reorient their bodies in order to reconfigure the F-formation and include the newcomer. As the conversation progresses, the participants use gaze cues to indicate they are paying attention to the speaker, address of their utterances, hold or release the conversational floor, and regulate intimacy~\citep{heylen2006head}. As demonstrated by~\citet{mutlu2012conversational}, the participants' gaze patterns reflect their conversational roles or \emph{footing}~\citep{goffman1979footing}---e.g., active participants (speakers and addressees) receive more gaze than bystanders or overhearers.

The objective of this research is to demonstrate that well-designed directed gaze behaviors can achieve the same effects in multiparty interactions between virtual agents and avatar-embodied humans in an immersive virtual environment, and thus motivate the need for such behaviors. Multiparty interactions are commonplace in online games and virtual worlds, such as Second Life~\citep{secondlife}. However, the nonverbal behaviors of characters and avatars in these applications tend to be fairly limited, mainly serving aesthetic functions rather than supporting interaction.
For example, it is not uncommon for multiple players in an online game to jointly interact with a non-player character (NPC). Yet the NPC generally lacks the ability to engage with the players in a true multiparty fashion. Usually the interaction proceeds in the form of a scripted dialog that does not acknowledge the multitude of individuals present, let alone allow them to contribute. Equipping NPCs with nonverbal cues that people rely on in multiparty, situated interaction will be an important step toward enabling richer storytelling in such contexts.

One obstacle to achieving natural interaction in virtual worlds has been the lack of precise, high-fidelity input methods, that would allow natural movement around the virtual environment, as well as tracking of users' nonverbal cues. Modern virtual reality devices for mass consumers such as the Oculus Rift~\citep{oculus} and HTC Vive~\citep{vive} are bringing with them high-fidelity, rotational and positional head tracking, which will enable more natural movement and visual exploration of the environment, as well as better inferences about the user's gaze direction and other nonverbal modalities. Moreover, immersion and wide fields of view enabled by modern VR headsets also bring with them heightened awareness of nonverbal behaviors displayed by virtual characters and avatars, further motivating the need for richer animated behaviors in immersive VR applications.

In this chapter, I give an overview of directed gaze behaviors designed for a virtual agent engaging in interaction with one or more parties in a virtual environment. The behaviors principally include body orientations shift for reconfiguring the conversational formation and gaze patterns for establishing footing. I present the results of an experiment with human participants demonstrating how a virtual agent using such behaviors can establish participants' footing in a multiparty interaction, thus shaping their participation behavior.
