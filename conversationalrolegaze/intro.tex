Shifts in eye gaze and body orientation are building blocks of key nonverbal behaviors humans rely on to initiate and conduct conversations. When two participants initiate a conversation, they position and orient their bodies in an F-formation~\citep{kendon1990conducting}, defined as a spatial arrangement creating a space between them to which they have equal, direct, and exclusive access. When another participant joins the conversation, the others reorient their bodies in order to reconfigure the F-formation and include the newcomer. As the conversation progresses, the participants' gaze patterns reflect their conversational roles or \emph{footing}~\citep{goffman1979footing}---as demonstrated by~\citet{mutlu2012conversational}, active participants (speakers and addressees) receive more gaze than bystanders or overhearers. Participants also use gaze cues to indicate they are paying attention to the speaker, address of their utterances, hold or release the conversational floor, and regulate intimacy~\citep{heylen2006head}.

The objective of this research is to demonstrate that well-designed directed gaze behaviors can achieve the same effects in multiparty interactions between virtual agents and avatar-embodied humans in a virtual environment, and thus motivate the need for such behaviors. Multiparty interactions are commonplace in online games and virtual worlds, such as Second Life~\citep{secondlife}. However, the nonverbal behaviors of characters and avatars in these applications tend to be fairly limited, mainly serving aesthetic functions rather than supporting interaction.
For example, it is not uncommon for multiple players in an online game to jointly interact with a non-player character (NPC). Yet the NPC generally lacks the ability to engage with the players in a true multiparty fashion. Usually the interaction proceeds in the form of a scripted dialog that does not acknowledge the multitude of individuals present, let alone allow them to contribute. Equipping NPCs with nonverbal cues that people rely on in multiparty, situated interaction will be an important step toward enabling richer storytelling in immersive online worlds.

One obstacle to achieving natural interaction in such contexts has been the lack of precise, high-fidelity input methods that can track users' nonverbal cues and allow more natural movement around the virtual environment. Modern virtual reality devices for mass consumers such as the Oculus Rift~\citep{oculus} and HTC Vive~\citep{vive} are bringing with them high-fidelity head and hand tracking, which will enable better inferences about the user's attention direction, gestures, and other nonverbal modalities. Moreover, immersion and high fields of view enabled by modern VR headsets also bring with them heightened awareness of nonverbal behaviors displayed by characters and avatars, further motivating the need for richer animated behaviors in immersive VR applications.

In this chapter, I give an overview of directed gaze behaviors designed for a virtual agent engaging in interaction with one or more parties in a virtual environment. The behaviors principally include body orientations shifts for reconfiguring the conversational formation and gaze patterns for establishing footing. I present the results of an experiment with human participants demonstrating how a virtual agent using such behaviors can establish participants' footing in a multiparty interaction, thus shaping their participation behavior.
