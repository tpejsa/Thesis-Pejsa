Shifts in eye gaze and body orientation are building blocks of key nonverbal behaviors humans rely on to initiate and conduct conversations. When two participants initiate a conversation, they position and orient their bodies in an F-formation~\citep{kendon1990conducting}, defined as a spatial arrangement creating a space between them to which they have equal, direct, and exclusive access. When another participant joins the conversation, the others reorient their bodies in order to reconfigure the F-formation and include the newcomer. As the conversation progresses, the participants' gaze patterns reflect their conversational roles or \emph{footing}~\citep{goffman1979footing}---as demonstrated by~\citet{mutlu2012conversational}, active participants (speakers and addressees) receive more gaze than bystanders or overhearers. Participants also use gaze cues to indicate they are paying attention to the speaker, address of their utterances, hold or release the conversational floor, and regulate intimacy~\citep{heylen2006head}.

It is the objective of this research to demonstrate that well-designed directed gaze behaviors can achieve the same effects in multiparty interactions between virtual agents and avatar-embodied humans in a virtual environment, and thus motivate the need for such behaviors. Multiparty interactions are commonplace in online games and virtual worlds, such as Second Life~\citep{secondlife}. However, the nonverbal behaviors of characters and avatars in these applications tend to be fairly limited, mainly serving aesthetic functions rather than supporting interaction. One obstacle to achieving natural interaction has been the lack of input methods that can track the users' nonverbal cues. The exploding popularity of consumer virtual reality devices such as the Oculus Rift~\citep{oculus} is also bringing with it high-fidelity, natural inputs such as head and hand tracking, which will enable better inferences about the user's attention direction, gestures, and other nonverbal modalities. The stereoscopic cues and high fields of view enabled by modern VR headsets also bring with them heightened awareness of nonverbal behaviors displayed by characters and avatars, further motivating the need for more natural multiparty interactions in immersive VR applications.

In this chapter, I give an overview of directed gaze behaviors designed for a virtual agent engaging in interaction with one or more parties in a virtual environment. The behaviors principally include body orientations shifts for reconfiguring the conversational formation and gaze patterns for establishing footing. I present the results of an experiment with human participants demonstrating how a virtual agent using such behaviors can establish participants' footing in a multiparty interaction, thus shaping their participation behavior.
