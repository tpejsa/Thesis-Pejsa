The current chapter has presented the models of gaze and body reorientation behaviors enabling a virtual agent to signal the conversational footing of human participants interacting with the agent.
The evaluation study has demonstrated that the introduced models are effective---a virtual agent equipped with them has the capability to influence users into conforming with their conversational role, making more conversational contributions as an addressee than bystander. This capability manifests itself specifically in the immersive VR setting. The effectiveness of the proposed behaviors in immersive VR is likely due to participants' increased awareness of the spatial arrangement of the interaction and the agent's gaze cues.

Implementers of conversational agents can use the described models to give agents the ability to more effectively manage multiparty interactions. The findings from this chapter also provide impetus for further research on behavioral mechanisms that allow such interactions to proceed smoothly and effectively. As the new generation of VR devices becomes more widely adopted, more nuanced multiparty interactions could become an integral part of social experiences in online games and virtual worlds. The current work represents a stepping stone toward understanding and implementing such interactions.

While the agent's footing behavior demonstrated in this chapter are effective at influencing participants' conversational behavior, they are still rudimentary compared to behaviors observed in real-world multiparty interactions. These interactions are characterized by much greater variations in spatial arrangement of participants, and supporting these variations on virtual agents will require more sophisticated behavior models for spatial positioning and orienting. Moreover, gaze behaviors in human interactions demonstrate complex contingencies that are not adequately described by first-order statistical models such as our own. Variables such as interpersonal distance, discourse structure, personality, gender, and many others influence human gaze, its timing, and spatial distribution. Supporting such complexity in gaze behaviors will require more sophisticated models built from more fine-grained observations of real humans.

Moreover, while our study suggests that a virtual agent's footing cues are only effective in immersive VR, it is unclear which aspects of the VR experience enable their effectiveness. While we speculate that the high field of view, stereopsis, and natural viewpoint control may all contribute, further studies are needed to analyze the individual effects of these features, and whether they impact social signals more generally. Future work may show that immersive, head-worn VR is not required to achieve believable multiparty interactions---e.g., high FOV can be achieved with an ultra-wide curved display, while head tracking can be performed with an encumbrance-free device such as TrackIR.\footnote{TrackIR, http://www.naturalpoint.com/trackir/}